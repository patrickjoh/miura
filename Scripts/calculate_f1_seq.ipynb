{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "labels = \"labels_TEMP_seq\"\n",
    "bucket_ano = \"anomalies\"\n",
    "dataset = \"repad2-temp-result-minmax\"\n",
    "detections = \"miura-temp-detection-standard\"\n",
    "margin = 3  # Margin of T values\n",
    "\n",
    "# Initialize client\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org)\n",
    "query_api = client.query_api()\n",
    "\n",
    "start_time = \"1997-04-10T00:00:00Z\"\n",
    "\n",
    "# Construct and fetch data\n",
    "queries = {\n",
    "    \"labels\": f'''\n",
    "        from(bucket: \"{bucket}\")\n",
    "        |> range(start: time(v: \"{start_time}\"))\n",
    "        |> filter(fn: (r) => r[\"_measurement\"] == \"{labels}\")\n",
    "        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "    ''',\n",
    "    \"dataset\": f'''\n",
    "        from(bucket: \"{bucket_ano}\")\n",
    "        |> range(start: time(v: \"{start_time}\"))\n",
    "        |> filter(fn: (r) => r[\"_measurement\"] == \"{dataset}\")\n",
    "        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "    ''',\n",
    "    \"detections\": f'''\n",
    "        from(bucket: \"{bucket_ano}\")\n",
    "        |> range(start: time(v: \"{start_time}\"))\n",
    "        |> filter(fn: (r) => r[\"_measurement\"] == \"{detections}\")\n",
    "        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "    '''\n",
    "}\n",
    "# Query data and store in dictionary\n",
    "results = {key: query_api.query_data_frame(query=queries[key]) for key in queries}\n",
    "\n",
    "# Check if any dataset is empty\n",
    "if any(df.empty for df in results.values()):\n",
    "    print(\"One or more datasets are empty. Check data and queries.\")\n",
    "else:\n",
    "    # Prepare datasets\n",
    "    for key, df in results.items():\n",
    "        df['timestamp'] = pd.to_datetime(df['_time'])\n",
    "\n",
    "    # Align T values with labels and sort by T (Time)\n",
    "    full_labels = pd.merge(results['dataset'], results['labels'], on='timestamp', how='inner')\n",
    "    full_labels = full_labels.sort_values(by='T')\n",
    "\n",
    "    # Create groups based on neighbouring T-values\n",
    "    full_labels['group'] = (full_labels['T'].diff() != 1).cumsum()\n",
    "\n",
    "    # Track detection matches for each group\n",
    "    group_matches = {group_id: False for group_id in full_labels['group'].unique()}\n",
    "\n",
    "    # Track detection and label matches\n",
    "    detection_matches = {index: False for index in results['detections'].index}\n",
    "    label_matches = {index: False for index in full_labels.index}\n",
    "\n",
    "    # Iterate over each anomaly group and check for detections within the margin\n",
    "    for group_id, group in full_labels.groupby('group'):\n",
    "        for index, detection in results['detections'].iterrows():\n",
    "            if any((detection['T'] >= row['T'] - margin) and (detection['T'] <= row['T'] + margin) for _, row in group.iterrows()):\n",
    "                detection_matches[index] = True\n",
    "                group_matches[group_id] = True # Event-wise match\n",
    "                label_matches.update({idx: True for idx, _ in group.iterrows()}) # Point-wise match\n",
    "\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    ## Point-wise calculation\n",
    "    true_positives  = sum(match for match in detection_matches.values())\n",
    "    false_negatives = sum(not match for match in label_matches.values())\n",
    "    false_positives = sum(not match for match in detection_matches.values())\n",
    "\n",
    "    ## Event-wise calculation (False positives are point-wise)\n",
    "    #true_positives  = sum(match for match in group_matches.values())\n",
    "    #false_negatives = sum(not match for match in group_matches.values())\n",
    "    #false_positives = sum(not match for match in detection_matches.values())\n",
    "\n",
    "\n",
    "    # Metrics calculations\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # For datasets with no anomalies\n",
    "    if (true_positives + false_positives + false_negatives) == 0:\n",
    "        print(\"No anomalies in dataset, and no detections made\")\n",
    "        precision = 1\n",
    "        recall = 1\n",
    "        f1_score = 1\n",
    "        \n",
    "\n",
    "    print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "    with open(f'../{labels}_{detections}.txt', 'w') as f:\n",
    "        print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}\", file=f)\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\", file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
