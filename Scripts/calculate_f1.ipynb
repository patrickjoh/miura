{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "labels = \"labels_CC2\"\n",
    "bucket_ano = \"anomalies\"\n",
    "dataset = \"repad2-cc2-result-minmax\"\n",
    "detections = \"repad2-cc2-detection-robust\"\n",
    "margin = 3  # Margin of T values\n",
    "\n",
    "# Initialize client\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org)\n",
    "query_api = client.query_api()\n",
    "\n",
    "start_time = \"1997-04-10T00:00:00Z\"\n",
    "\n",
    "# Construct the Flux query\n",
    "query_labels = f'''\n",
    "from(bucket: \"{bucket}\")\n",
    "    |> range(start: time(v: \"{start_time}\"))\n",
    "    |> filter(fn: (r) => r[\"_measurement\"] == \"{labels}\")\n",
    "    |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "'''\n",
    "\n",
    "# Construct the Flux query\n",
    "query_dataset = f'''\n",
    "from(bucket: \"{bucket_ano}\")\n",
    "    |> range(start: time(v: \"{start_time}\"))\n",
    "    |> filter(fn: (r) => r[\"_measurement\"] == \"{dataset}\")\n",
    "    |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "'''\n",
    "\n",
    "# Construct the Flux query\n",
    "query_detections = f'''\n",
    "from(bucket: \"{bucket_ano}\")\n",
    "    |> range(start: time(v: \"{start_time}\"))\n",
    "    |> filter(fn: (r) => r[\"_measurement\"] == \"{detections}\")\n",
    "    |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "'''\n",
    "\n",
    "# Fetch data\n",
    "result_dataset = query_api.query_data_frame(query=query_dataset)\n",
    "result_labels = query_api.query_data_frame(query=query_labels)\n",
    "result_detections = query_api.query_data_frame(query=query_detections)\n",
    "\n",
    "# Check if any dataset is empty\n",
    "if result_dataset.empty or result_detections.empty or result_labels.empty:\n",
    "    print(\"One or more datasets are empty. Check data and queries.\")\n",
    "else:\n",
    "    # Prepare datasets\n",
    "    result_dataset['timestamp'] = pd.to_datetime(result_dataset['_time'])\n",
    "    result_labels['timestamp'] = pd.to_datetime(result_labels['_time'])\n",
    "    result_detections['timestamp'] = pd.to_datetime(result_detections['_time'])\n",
    "\n",
    "    # Merge to align T values with labels\n",
    "    full_labels = pd.merge_asof(result_labels.sort_values('timestamp'), result_dataset[['timestamp', 'T']].sort_values('timestamp'), on='timestamp', direction='nearest')\n",
    "\n",
    "    # Track detection matches\n",
    "    detection_matches = {index: False for index in result_detections.index}\n",
    "    label_matches = {index: False for index in full_labels.index}\n",
    "\n",
    "    # Identify true positives and update match status\n",
    "    for index, label_row in full_labels.iterrows():\n",
    "        # Find detections within the margin\n",
    "        detections_in_margin = result_detections[\n",
    "            (result_detections['T'] >= label_row['T'] - margin) & \n",
    "            (result_detections['T'] <= label_row['T'] + margin)\n",
    "        ]\n",
    "        if not detections_in_margin.empty:\n",
    "            label_matches[index] = True\n",
    "            for det_index in detections_in_margin.index:\n",
    "                detection_matches[det_index] = True\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives  = sum(match for match in label_matches.values())\n",
    "    false_negatives = sum(not match for match in label_matches.values())\n",
    "    false_positives = sum(not match for match in detection_matches.values())\n",
    "\n",
    "    # Calculating Precision, Recall, and F1 Score\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # For datasets with no anomalies\n",
    "    if true_positives + false_negatives + false_negatives  == 0:\n",
    "        precision = 1\n",
    "        recall = 1\n",
    "        f1_score = 1\n",
    "        print(\"No anomalies in dataset, and no detections made\")\n",
    "\n",
    "    print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "    with open(f'../{detections}.txt', 'w') as f:\n",
    "        print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}\", file=f)\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\", file=f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
