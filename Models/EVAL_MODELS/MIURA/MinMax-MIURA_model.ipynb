{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MinMax_LSTM_inc_model import LSTM_inc\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from collections import deque\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import ASYNCHRONOUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RePAD2\n",
    "def calculate_aare(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the Absolute Relative Error (ARE) between an actual and predicted value.\n",
    "    \n",
    "    Parameters:\n",
    "    actual (deque): The actual value.\n",
    "    predicted (deque): The predicted value.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Absolute Relative Error.\n",
    "    \"\"\"\n",
    "    # Adding a small value epsilon to avoid division by zero\n",
    "    aare_values = []\n",
    "\n",
    "    # To test with only a single value of actual and predicted to calculate AARE\n",
    "    #actual = actual[-1]\n",
    "    #predicted = predicted[-1]\n",
    "    \n",
    "    for act, pred in zip(actual, predicted):\n",
    "        AARE = abs(act - pred) / max(abs(act), 1)\n",
    "        aare_values.append(AARE)\n",
    "\n",
    "    mean_aare = np.mean(aare_values)\n",
    "\n",
    "    return mean_aare\n",
    "\n",
    "\n",
    "def calculate_threshold(aare_values):\n",
    "    \"\"\"\n",
    "    Calculate the threshold value (Thd) based on a deque of AARE values.\n",
    "    Thd is defined as the mean of the AARE values plus three times their standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - aare_values (array-like): An array of AARE values.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated threshold value (Thd).\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation of the AARE values\n",
    "    mean_aare = np.mean(aare_values)\n",
    "    std_aare = np.std(aare_values)\n",
    "    \n",
    "    # Calculate Thd\n",
    "    thd = mean_aare + 3 * std_aare\n",
    "    \n",
    "    return thd\n",
    "\n",
    "# Function for initializing the model\n",
    "def initialize(train_events):\n",
    "    tensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "    tensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "    # Create an instance of the LSTM model\n",
    "    model = LSTM_inc(input_size=1, hidden_size=10, num_layers=1, output_size=1, num_epochs=50, learning_rate=0.005)\n",
    "\n",
    "    model.initialize(tensor_x, tensor_y) # Train the model\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function for incrementally updating the model\n",
    "def update_model(model, train_events):\n",
    "    tensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "    tensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "    model.continue_training(tensor_x, tensor_y) # Continue training the model\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function for reporting anomalies to InfluxDB\n",
    "def report_anomaly(T, timestamp, actual_value, predicted_value, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"miura-temp-detection-minmax\")\\\n",
    "        .tag(\"host\", \"detector\")\\\n",
    "        .field(\"T\", float(T))\\\n",
    "        .field(\"actual_value\", float(actual_value))\\\n",
    "        .field(\"predicted_value\", float(predicted_value))\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    #write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "    #print(f\"Anomalous event sent to InfluxDB: Value={value}, Time={timestamp}\")\n",
    "\n",
    "def write_result(timestamp, T, actual_value, predicted_value, AARE, Thd, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"miura-temp-result-minmax\")\\\n",
    "        .tag(\"host\", \"detector\")\\\n",
    "        .field(\"T\", float(T))\\\n",
    "        .field(\"actual_value\", float(actual_value))\\\n",
    "        .field(\"predicted_value\", float(predicted_value))\\\n",
    "        .field(\"AARE\", float(AARE))\\\n",
    "        .field(\"Thd\", float(Thd))\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    #write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "    #print(f'T: {T}, Real Value: {actual_value}, Prediction Value: {predicted_value}, AARE: {AARE}, Thd: {Thd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPAD2 Algorithm ###\n",
    "\n",
    "\"\"\"\n",
    "THE PLAN\n",
    "\n",
    "Making the program start from any predefined time, and then continue to fetch data from that time and onwards.\n",
    "And so it can process older data and then catch up to the present time.\n",
    "\n",
    "It therefore processes a batch of 3 from the earliest timestamp in the range, and then updates the start time for the next iteration \n",
    "by incrementing the start time by a set time to both avoid duplicate events and to eventually catch up to the present time.\n",
    "\n",
    "The program will run indefinitely, and will continue to fetch data from the InfluxDB and process it in batches of 3 until the program is stopped.\n",
    "I there are not enough events for a batch, the program will wait for a set time before trying again.\n",
    "When a batch of three is available it will be processed and the it will again wait for another event to be available.\n",
    "\n",
    "This way it is both flexible and efficient, and can be easily used to process either data in real-time or historical data\n",
    "\n",
    "\n",
    "For each batch it follows the algorithm of RePAD2\n",
    "\n",
    "\n",
    "To-Do:\n",
    "\n",
    "Store actual values (Store whole event?) with predicted values in sliding window \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Testing of InfluxDB with LSTM\n",
    "# MÃ¥ installeres influxdb-client \"pip install influxdb-client\"\n",
    "# https://www.influxdata.com/blog/getting-started-with-python-and-influxdb-v2-0/\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "measurement = \"CC2\"\n",
    "\n",
    "# Instantiate the QueryAPI\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "write_api = client.write_api(write_options=ASYNCHRONOUS)\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Sliding window for Threshold\n",
    "actual_value = deque([0] * 3, maxlen=3)\n",
    "predicted_value = deque([0] * 3, maxlen=3)\n",
    "sliding_window_AARE = deque(maxlen=8064)\n",
    "\n",
    "# Other data structures\n",
    "batch_events = deque(maxlen=3)\n",
    "next_event = None\n",
    "\n",
    "# For printing the values\n",
    "AARE_T = 0\n",
    "Thd = 0\n",
    "\n",
    "# Time parameters\n",
    "poll_interval = 1  # Second(s)\n",
    "time_increment = 1 # Second(s)\n",
    "start_time = \"1997-04-10T00:00:00Z\"\n",
    "\n",
    "# RePAD2 specific\n",
    "T = 0\n",
    "flag = True\n",
    "M = None # Model\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "all_times = []\n",
    "under_threshold_times = []\n",
    "training_required = []\n",
    "model_event_count = 0\n",
    "model_train_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Construct the Flux query\n",
    "    query = f'''\n",
    "    from(bucket: \"{bucket}\")\n",
    "     |> range(start: time(v: \"{start_time}\"))\n",
    "     |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "    '''\n",
    "        \n",
    "    # Query the data\n",
    "    events = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "    if len(events) > 1: # Need at least 4 to predict next and compar\n",
    "\n",
    "        for i in range(len(events)-1):\n",
    "\n",
    "            start_processing_time = time.time() # EVAL - Start timing for processing the batch\n",
    "\n",
    "            batch_events.append(events[i])\n",
    "            next_event = events[i+1]     \n",
    "\n",
    "        # RePAD2 Algorithm\n",
    "\n",
    "        # Set T to the length of the sliding \n",
    "            if T >= 2 and T < 5: # 3 total values when T = 2\n",
    "                if T == 2:\n",
    "                    # Initialize the model\n",
    "                    M = initialize([event.get_value() for event in list(batch_events)])\n",
    "                else: \n",
    "                    M = update_model(M, [event.get_value() for event in list(batch_events)])\n",
    "                pred_D_T_plus_1 = M.predict_next()\n",
    "                # Append the event and its prediction to the sliding window\n",
    "                actual_value.append(next_event.get_value())\n",
    "                predicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "            elif T >= 5 and T < 7:\n",
    "                # Calculate AARE and append to sliding window\n",
    "                AARE_T = calculate_aare(actual_value, predicted_value)\n",
    "                sliding_window_AARE.append(AARE_T)\n",
    "                M = update_model(M, [event.get_value() for event in list(batch_events)])\n",
    "                pred_D_T_plus_1 = M.predict_next()\n",
    "                # Append the event and its prediction to the sliding window\n",
    "                actual_value.append(next_event.get_value())\n",
    "                predicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "            elif T >= 7 and flag == True:\n",
    "                if T != 7: # Use M to precdict D_T\n",
    "                    pred_D_T = M.predict_next()\n",
    "                    # Append the event and its prediction to the sliding window\n",
    "                    actual_value.append(next_event.get_value())\n",
    "                    predicted_value.append(pred_D_T)\n",
    "\n",
    "                # Calculate AARE and append to sliding window\n",
    "                AARE_T = calculate_aare(actual_value, predicted_value)\n",
    "                sliding_window_AARE.append(AARE_T)\n",
    "                # Calculate Thd\n",
    "                Thd = calculate_threshold(sliding_window_AARE)\n",
    "                \n",
    "                if AARE_T <= Thd: pass # Calculate AARE and append to sliding window\n",
    "                else:\n",
    "                    # Train an LSTM model with D_T-3, D_T-2, D_T-1\n",
    "                    model = update_model(M, [event.get_value() for event in list(batch_events)])\n",
    "                    # Use the model to predict D_T\n",
    "                    pred_D_T = model.predict_next()\n",
    "                    \n",
    "                    # Append the event and its prediction to the sliding window\n",
    "                    actual_value.append(next_event.get_value())\n",
    "                    predicted_value.append(pred_D_T)\n",
    "\n",
    "                    # Re-calculate AARE_T\n",
    "                    AARE_T = calculate_aare(actual_value, predicted_value)\n",
    "                    sliding_window_AARE.append(AARE_T)\n",
    "                    # Re-calculate Thd\n",
    "                    Thd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "                    model_train_count += 1 # EVAL - Increment the model training count\n",
    "\n",
    "                    if AARE_T <= Thd:\n",
    "                        # D_T is not reported as anomaly\n",
    "                        # Replace M with the new model\n",
    "                        M = model\n",
    "                        # Update flag to True\n",
    "                        flag = True\n",
    "\n",
    "                    else:\n",
    "                        # D_T reported as anomaly immediately\n",
    "                        report_anomaly(T+1, next_event.get_time(), actual_value[-1], predicted_value[-1], write_api)\n",
    "                        # Update flag to False\n",
    "                        flag = False\n",
    "            \n",
    "            elif T >= 7 and flag == False:\n",
    "                # Train an LSTM model with D_T-3, D_T-2, D_T-1\n",
    "                model = update_model(M, [event.get_value() for event in batch_events])\n",
    "                # Use the model to predict D_T\n",
    "                pred_D_T = model.predict_next()\n",
    "                # Append the event and its prediction to the sliding window\n",
    "                actual_value.append(next_event.get_value())\n",
    "                predicted_value.append(pred_D_T)\n",
    "\n",
    "                # Calculate AARE_T\n",
    "                AARE_T = calculate_aare(actual_value, predicted_value)\n",
    "                sliding_window_AARE.append(AARE_T)\n",
    "                # Calculate Thd\n",
    "                Thd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "                model_train_count += 1 # EVAL - Increment the model training count\n",
    "\n",
    "                if AARE_T <= Thd:\n",
    "                    # D_T is not reported as anomaly\n",
    "                    # Replace M with the new model\n",
    "                    M = model\n",
    "                    # Update flag to True\n",
    "                    flag = True\n",
    "\n",
    "                else:\n",
    "                    # D_T reported as anomaly immediately\n",
    "                    report_anomaly(T+1, next_event.get_time(), actual_value[-1], predicted_value[-1], write_api)\n",
    "                    # Update flag to False\n",
    "                    flag = False\n",
    "\n",
    "\n",
    "            end_time = time.time()\n",
    "            process_time = end_time - start_processing_time # EVAL - Time to process the batch\n",
    "            all_times.append(process_time) # EVAL - Append the time to the list of all times\n",
    "\n",
    "\n",
    "            if AARE_T <= Thd: # EVAL - Add to the list of times under the threshold\n",
    "                under_threshold_times.append(process_time)\n",
    "            else:\n",
    "                # EVAL - Append the time to list of times when training was required\n",
    "                training_required.append(time.time() - start_processing_time)\n",
    "\n",
    "            # Write the results to InfluxDB\n",
    "            write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-2], AARE_T, Thd, write_api) \n",
    "\n",
    "            # Increment T\n",
    "            T += 1\n",
    "\n",
    "        # Update start time for the next iteration\n",
    "        last_event_time = batch_events[-1].get_time()\n",
    "        # Increment by 1 second to avoid duplicate events\n",
    "        start_time = (last_event_time + timedelta(seconds=time_increment)).isoformat()\n",
    "\n",
    "    else:\n",
    "        print(\"No events found in range.\")\n",
    "        break\n",
    "\n",
    "    time.sleep(poll_interval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process evaluation data\n",
    "\n",
    "# Use to not run cell when \"Run All\"\n",
    "#raise SystemExit(\"Stop right here!\")\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Average time consumption and standard deviation for each event, regardless of AARE\n",
    "average_batch_time = (sum(all_times) / len(all_times)) if all_times else 0\n",
    "std_batch_time = np.std(all_times) if all_times else 0 \n",
    "\n",
    "# Average time consumption and standard deviation when AARE <= Thd \n",
    "average_under_thd_time = (sum(under_threshold_times) / len(under_threshold_times)) if under_threshold_times else 0\n",
    "std_under_thd_time = np.std(under_threshold_times) if under_threshold_times else 0\n",
    "\n",
    "# Average time consumption and standard deviation when AARE > Thd \n",
    "average_training_required = (sum(training_required) / len(training_required)) if training_required else 0\n",
    "std_training_required = np.std(training_required) if training_required else 0\n",
    "\n",
    "\n",
    "# LSTM model retraining ratio\n",
    "retraining_ratio = (model_train_count / len(all_times)) if all_times else 0\n",
    "\n",
    "\n",
    "# Create a DataFrame to organize these results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Average (sec)\": [\n",
    "        average_batch_time,\n",
    "        average_under_thd_time, \n",
    "        average_training_required, \n",
    "        retraining_ratio\n",
    "    ],\n",
    "    \"Standard Deviation (sec)\": [\n",
    "        std_batch_time,\n",
    "        std_under_thd_time, \n",
    "        std_training_required, \n",
    "        f\"(={model_train_count}/{len(all_times)})\"\n",
    "    ]\n",
    "}, index=[\n",
    "    \"Average Time per Event\",\n",
    "    \"Average Time when AARE <= Thd\",\n",
    "    \"Average Time when Training is Required\",\n",
    "    \"LSTM Model Retraining Ratio\"\n",
    "])\n",
    "\n",
    "#results_df\n",
    "\n",
    "results_md = tabulate(results_df, headers='keys', tablefmt='pipe')\n",
    "\n",
    "print(results_md)\n",
    "\n",
    "#\n",
    "#with open(f'../Timing/{measurement}_miura_robust', 'w') as f:\n",
    "#    f.write(results_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
