{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data \n",
    "x_values = torch.tensor([1, 2, 3, 4], dtype=torch.float32).view(-1, 1, 1)\n",
    "y_values = torch.tensor([10, 20, 30, 40], dtype=torch.float32).view(-1, 1, 1)\n",
    "\n",
    "# Create a scaler\n",
    "sc_x = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "\n",
    "# Shape the data from 3D to 2D\n",
    "x_values_2D = x_values.squeeze(-1).numpy()\n",
    "y_values_2D = y_values.squeeze(-1).numpy()\n",
    "\n",
    "# Fit the scaler and transform the data\n",
    "x_scaled = sc_x.fit_transform(x_values_2D)\n",
    "y_scaled = sc_y.fit_transform(y_values_2D)\n",
    "\n",
    "# Reshape the data back to 3D and convert to tensor\n",
    "x_scaled = torch.tensor(x_scaled).unsqueeze(-1)\n",
    "y_scaled = torch.tensor(y_scaled).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :]) # Extract only the last timestep's output for prediction\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_scaled, y_scaled):\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.05\n",
    "\n",
    "    input_size = 1\n",
    "    hidden_size = 10\n",
    "    num_layers = 1\n",
    "\n",
    "    num_classes = 1\n",
    "\n",
    "    # Initialize the model\n",
    "    model = SimpleLSTM(input_size, hidden_size, num_classes, num_layers)\n",
    "    # Initialize the optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.MSELoss() # Mean Squared Error Loss\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set the model to training mode\n",
    "        optimizer.zero_grad() # Clear the gradients\n",
    "        output = model(x_scaled) # Forward pass\n",
    "        loss = loss_fn(output, y_scaled.view(-1, 1)) # Compute the loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Update the weights\n",
    "        \n",
    "        if epoch % 5 == 0: # Print the loss every 5 epochs\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(x_scaled, y_scaled) # Train the model\n",
    "\n",
    "# Your manually specified actual_y values\n",
    "actual_y = np.array([10, 20, 30, 40, 50])  # Example actual y values for x values [1, 2, 3, 4]\n",
    "\n",
    "# Assuming `sc_x` and `sc_y` are already fitted to your training data\n",
    "# Prepare multiple x values for prediction\n",
    "x_to_predict = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32).view(-1, 1, 1)  # Example x values\n",
    "x_to_predict_2D = x_to_predict.squeeze(-1).numpy()  # Convert to 2D for scaling\n",
    "x_to_predict_scaled = sc_x.transform(x_to_predict_2D)  # Scale x values\n",
    "x_to_predict_scaled_tensor = torch.tensor(x_to_predict_scaled, dtype=torch.float32).view(-1, 1, 1)  # Convert back to tensor\n",
    "\n",
    "model.eval()    # Set the model to evaluation mode\n",
    "predictions_scaled = [] # Store the scaled predictions\n",
    "with torch.no_grad():  # Disable gradient tracking\n",
    "    for x_val in x_to_predict_scaled_tensor: # Iterate over each x value\n",
    "        prediction_scaled = model(x_val.unsqueeze(0))  # Add batch dimension\n",
    "        predictions_scaled.append(prediction_scaled) # Store the scaled prediction\n",
    "\n",
    "# Convert predictions to a numpy array for inverse transform\n",
    "predictions_scaled_np = torch.cat(predictions_scaled, dim=0).numpy()\n",
    "predictions = sc_y.inverse_transform(predictions_scaled_np.reshape(-1, 1))  # Inverse transform predictions\n",
    "\n",
    "# Print Actual vs Predicted\n",
    "predicted_y = predictions.flatten()\n",
    "\n",
    "# Print the actual and predicted values\n",
    "print(\"X Value\\tActual Y\\tPredicted Y\")\n",
    "for i, x_val in enumerate(x_to_predict.numpy().flatten()):\n",
    "    print(f\"{x_val}\\t{actual_y[i]}\\t{predicted_y[i]}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_to_predict.numpy().flatten(), actual_y, 'bo-', label='Actual')\n",
    "plt.plot(x_to_predict.numpy().flatten(), predicted_y, 'ro-', label='Predicted')\n",
    "plt.title('LSTM Predictions vs Actual')\n",
    "plt.xlabel('X Value')\n",
    "plt.ylabel('Y Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
