{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Load data\n",
    "x_values = torch.tensor([1, 2, 3]) # X values\n",
    "y_values = torch.tensor([20, 30, 40]) # Y values\n",
    "\n",
    "x_values_np = x_values.numpy()\n",
    "y_values_np = y_values.numpy()\n",
    "\n",
    "# Plot data\n",
    "plt.plot(x_values_np, y_values_np)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Values over time')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data \n",
    "x_values = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1) # X values\n",
    "y_values = x_values * 2 # Y values\n",
    "\n",
    "# Test data\n",
    "#x_test = torch.tensor([1, 2, 3, 4, 5, 6], dtype=torch.float32).view(-1, 1, 1) # X values\n",
    "#y_test = x_test * 10 # Y values\n",
    "\n",
    "print(x_values)\n",
    "\n",
    "\n",
    "sc_x = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "\n",
    "# Shape the data from 3D to 2D\n",
    "x_values_2D = x_values.squeeze(-1).numpy()\n",
    "y_values_2D = y_values.squeeze(-1).numpy()\n",
    "\n",
    "# Fit the scaler and transform the data\n",
    "x_scaled = sc_x.fit_transform(x_values_2D)\n",
    "y_scaled = sc_y.fit_transform(y_values_2D)\n",
    "\n",
    "# Reshape the data back to 3D and convert to tensor\n",
    "x_scaled = torch.tensor(x_scaled).unsqueeze(-1)\n",
    "y_scaled = torch.tensor(y_scaled).unsqueeze(-1)\n",
    "\n",
    "# Print shapes\n",
    "print(x_scaled)\n",
    "print(y_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        #x, _ = self.lstm(x)\n",
    "        # Extract only the last timestep's output for prediction\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.05\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 10\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleLSTM(input_size, hidden_size, num_classes, num_layers)\n",
    "#model = SimpleGRU()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_scaled)\n",
    "    loss = loss_fn(output, y_scaled.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `sc_x` and `sc_y` are already fitted to your training data\n",
    "# Prepare multiple x values for prediction\n",
    "x_to_predict = torch.tensor([1, 2, 3, 4], dtype=torch.float32).view(-1, 1, 1)  # Example x values\n",
    "x_to_predict_2D = x_to_predict.squeeze(-1).numpy()  # Convert to 2D for scaling\n",
    "x_to_predict_scaled = sc_x.transform(x_to_predict_2D)  # Scale x values\n",
    "x_to_predict_scaled_tensor = torch.tensor(x_to_predict_scaled, dtype=torch.float32).view(-1, 1, 1)  # Convert back to tensor\n",
    "\n",
    "model.eval()\n",
    "predictions_scaled = []\n",
    "with torch.no_grad():\n",
    "    for x_val in x_to_predict_scaled_tensor:\n",
    "        prediction_scaled = model(x_val.unsqueeze(0))  # Add batch dimension\n",
    "        predictions_scaled.append(prediction_scaled)\n",
    "\n",
    "# Convert predictions to a numpy array for inverse transform\n",
    "predictions_scaled_np = torch.cat(predictions_scaled, dim=0).numpy()\n",
    "predictions = sc_y.inverse_transform(predictions_scaled_np.reshape(-1, 1))  # Inverse transform predictions\n",
    "\n",
    "# Print Actual vs Predicted\n",
    "actual_y = (x_to_predict * 2).numpy().flatten()  # Replace with actual calculation or data as needed\n",
    "predicted_y = predictions.flatten()\n",
    "\n",
    "print(\"X Value\\tActual Y\\tPredicted Y\")\n",
    "for i, x_val in enumerate(x_to_predict.numpy().flatten()):\n",
    "    print(f\"{x_val}\\t{actual_y[i]}\\t{predicted_y[i]}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_to_predict.numpy().flatten(), actual_y, 'bo-', label='Actual')\n",
    "plt.plot(x_to_predict.numpy().flatten(), predicted_y, 'ro-', label='Predicted')\n",
    "plt.title('LSTM Predictions vs Actual')\n",
    "plt.xlabel('X Value')\n",
    "plt.ylabel('Y Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
