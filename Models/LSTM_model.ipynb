{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data \n",
    "x_values = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "y_values = torch.tensor([10, 20, 30], dtype=torch.float32).view(-1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, x_values, y_values, input_size, hidden_size, num_layers, output_size, batch_size=3, num_epochs=50, learning_rate=0.05):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Initialize scalers\n",
    "        self.sc_x = RobustScaler()\n",
    "        self.sc_y = RobustScaler()\n",
    "        \n",
    "        # Preprocess the data\n",
    "        self.x_scaled, self.y_scaled = self.fit_transform(x_values, y_values)\n",
    "        \n",
    "        # Create DataLoader\n",
    "        self.train_loader = self.create_dataloader(self.x_scaled, self.y_scaled, batch_size)\n",
    "        \n",
    "        # LSTM Model Configuration\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Define LSTM and FC layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def fit_transform(self, x_values, y_values):\n",
    "\n",
    "        # Ensure input is in NumPy format\n",
    "        if not isinstance(x_values, np.ndarray):\n",
    "            x_values = x_values.numpy()\n",
    "        if not isinstance(y_values, np.ndarray):\n",
    "            y_values = y_values.numpy()\n",
    "\n",
    "        # Scale the data\n",
    "        x_values_2D = x_values.squeeze(-1).numpy()\n",
    "        y_values_2D = y_values.squeeze(-1).numpy()\n",
    "        \n",
    "        x_scaled = self.sc_x.fit_transform(x_values_2D)\n",
    "        y_scaled = self.sc_y.fit_transform(y_values_2D)\n",
    "        \n",
    "        x_scaled = torch.tensor(x_scaled).unsqueeze(-1)\n",
    "        y_scaled = torch.tensor(y_scaled).unsqueeze(-1)\n",
    "        \n",
    "        return x_scaled, y_scaled\n",
    "    \n",
    "    def transform(self, x_values):\n",
    "        # Ensure input is in NumPy format\n",
    "        if not isinstance(x_values, np.ndarray):\n",
    "            x_values = x_values.numpy()\n",
    "\n",
    "        x_values_2D = x_values.squeeze(-1).numpy()\n",
    "        x_scaled = self.sc_x.transform(x_values_2D)\n",
    "        x_scaled = torch.tensor(x_scaled).unsqueeze(-1)\n",
    "        return x_scaled\n",
    "\n",
    "    def create_dataloader(self, x_scaled, y_scaled, batch_size):\n",
    "        class CustomDataset(Dataset):\n",
    "            def __init__(self, x_data, y_data):\n",
    "                self.x_data = x_data\n",
    "                self.y_data = y_data\n",
    "            \n",
    "            def __len__(self):\n",
    "                return len(self.x_data)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                return self.x_data[idx], self.y_data[idx]\n",
    "        \n",
    "        dataset = CustomDataset(x_scaled, y_scaled)\n",
    "        return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  # Extract only the last timestep's output for prediction\n",
    "        return x\n",
    "\n",
    "    def inverse_transform_y(self, y_pred):\n",
    "        # Ensure input is in NumPy format\n",
    "        if not isinstance(y_pred, np.ndarray):\n",
    "            y_pred = y_pred.numpy()\n",
    "\n",
    "        # Convert predictions back to original scale\n",
    "        y_pred_np = y_pred.detach().numpy()  # Convert to numpy array\n",
    "        y_pred_orig = self.sc_y.inverse_transform(y_pred_np)\n",
    "        return torch.tensor(y_pred_orig)\n",
    "\n",
    "    def train_model(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        loss_fn = nn.MSELoss()  # Mean Squared Error Loss\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train()  # Set the model to training mode\n",
    "            for x, y in self.train_loader:\n",
    "                output = self(x)  # Forward pass\n",
    "                optimizer.zero_grad()  # Clear the gradients\n",
    "                loss = loss_fn(output, y.view(-1, 1))  # Compute the loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update the weights\n",
    "\n",
    "            if epoch % 5 == 0:  # Print the loss every 5 epochs\n",
    "                print(f'Epoch [{epoch}/{self.num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the LSTM model\n",
    "model = LSTM(x_values, y_values, input_size=1, hidden_size=10, num_layers=1, output_size=1, batch_size=3, num_epochs=50, learning_rate=0.01)\n",
    "model.train_model() # Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a prediction\n",
    "x_test = torch.tensor([4], dtype=torch.float32).view(-1, 1, 1)\n",
    "x_test = model.transform(x_test)\n",
    "y_pred = model(x_test)\n",
    "y_pred_orig = model.inverse_transform_y(y_pred)\n",
    "\n",
    "print(f'Prediction: {y_pred_orig.item()}')  # Prediction: 40.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
