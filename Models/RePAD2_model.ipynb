{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_model import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from influxdb_client import InfluxDBClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of LSTM-class\n",
    "x_values = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "y_values = torch.tensor([10, 20, 30], dtype=torch.float32).view(-1, 1, 1)\n",
    "\n",
    "# Create an instance of the LSTM model\n",
    "model = LSTM(x_values, y_values, input_size=1, hidden_size=10, num_layers=1, output_size=1, batch_size=3, num_epochs=50, learning_rate=0.01)\n",
    "model.train_model() # Train the model\n",
    "\n",
    "# Get a prediction\n",
    "x_test = torch.tensor([4], dtype=torch.float32).view(-1, 1, 1)\n",
    "x_test = model.transform(x_test)\n",
    "y_pred = model(x_test)\n",
    "y_pred_orig = model.inverse_transform_y(y_pred)\n",
    "\n",
    "print(f'Prediction: {y_pred_orig.item()}')  # Prediction: 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of InfluxDB\n",
    "# Må installeres influxdb-client \"pip install influxdb-client\"\n",
    "# https://www.influxdata.com/blog/getting-started-with-python-and-influxdb-v2-0/\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "\n",
    "poll_interval = 1\n",
    "\n",
    "# Instantiate the QueryAPI\n",
    "query_api = client.query_api()\n",
    "\n",
    "batch_nr = 0\n",
    "\n",
    "# Initialize timestamp\n",
    "# Ensure last_timestamp is a datetime object for accurate comparison\n",
    "last_timestamp = datetime.fromisoformat(\"1970-01-01T00:00:00+00:00\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Construct the Flux query\n",
    "    query = f'''\n",
    "    from(bucket: \"{bucket}\")\n",
    "     |> range(start: time(v: \"2014-04-10T00:00:00Z\"))\n",
    "     |> filter(fn: (r) => r[\"_measurement\"] == \"cpu_utilization\")\n",
    "     |> tail(n: 3)\n",
    "    '''\n",
    "            \n",
    "\n",
    "    # Query the data\n",
    "    events = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "    \n",
    "\n",
    "    if events:\n",
    "        # Extract the timestamp of the last event\n",
    "        new_last_event = events[-1]\n",
    "        new_last_timestamp = new_last_event.get_time()  # This should already be a datetime object\n",
    "\n",
    "        # Compare datetime objects directly\n",
    "        if new_last_timestamp > last_timestamp:\n",
    "            # Increment batch_nr\n",
    "            batch_nr += 1\n",
    "            # Print batch nr as seperator\n",
    "            print(\"Batch nr: \", batch_nr)\n",
    "\n",
    "            # New event detected\n",
    "            for event in events:\n",
    "                # Print the timestamp and value of the event\n",
    "                print(f'Time: {event.get_time()}, Value: {event.get_value()}')\n",
    "\n",
    "            # Update last_timestamp for the next iteration, converting back to ISO format if necessary\n",
    "            last_timestamp = new_last_timestamp \n",
    "\n",
    "       # else:\n",
    "            #print(\"No new events found.\")\n",
    "    else:\n",
    "        print(\"No events found in range.\")\n",
    "\n",
    "    time.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "THE PLAN\n",
    "\n",
    "Making the program start from any predefined time, and then continue to fetch data from that time and onwards.\n",
    "And so it can process older data and then catch up to the present time.\n",
    "\n",
    "It therefore processes a batch of 3 from the earliest timestamp in the range, and then updates the start time for the next iteration \n",
    "by incrementing the start time by a set time to both avoid duplicate events and to eventually catch up to the present time.\n",
    "\n",
    "The program will run indefinitely, and will continue to fetch data from the InfluxDB and process it in batches of 3 until the program is stopped.\n",
    "I there are not enough events for a batch, the program will wait for a set time before trying again.\n",
    "When a batch of three is available it will be processed and the it will again wait for another event to be available.\n",
    "\n",
    "This way it is both flexible and efficient, and can be easily used to process either data in real-time or historical data\n",
    "\n",
    "\n",
    "For each batch it follows the algorithm of RePAD2\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Testing of InfluxDB with LSTM\n",
    "# Må installeres influxdb-client \"pip install influxdb-client\"\n",
    "# https://www.influxdata.com/blog/getting-started-with-python-and-influxdb-v2-0/\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "\n",
    "poll_interval = 1\n",
    "time_increment = 1\n",
    "\n",
    "# Instantiate the QueryAPI\n",
    "query_api = client.query_api()\n",
    "\n",
    "batch_nr = 0\n",
    "\n",
    "# Initialize timestamp\n",
    "# Ensure last_timestamp is a datetime object for accurate comparison\n",
    "last_timestamp = datetime.fromisoformat(\"1970-01-01T00:00:00+00:00\")\n",
    "start_time = \"2014-04-10T00:00:00Z\"\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Construct the Flux query\n",
    "    query = f'''\n",
    "    from(bucket: \"{bucket}\")\n",
    "     |> range(start: time(v: \"{start_time}\"))\n",
    "     |> filter(fn: (r) => r[\"_measurement\"] == \"cpu_utilization\")\n",
    "    '''\n",
    "        \n",
    "    # Query the data\n",
    "    events = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "    if events:\n",
    "        # Process batches of 3 until there are not enough events for a batch\n",
    "        for i in range(len(events) - 2):\n",
    "            # Select the batch of 3 events\n",
    "            batch_events = events[i:i+3]\n",
    "\n",
    "            # Process events\n",
    "            # Example of processing the events\n",
    "            # Print batch nr as seperator\n",
    "            batch_nr += 1\n",
    "            print(\"Batch nr: \", batch_nr)\n",
    "            for event in batch_events:\n",
    "\n",
    "                # Print the timestamp and value of the event\n",
    "                print(f'Time: {event.get_time()}, Value: {event.get_value()}')\n",
    "\n",
    "            # After processing the event\n",
    "            if i + 3 >= len(events):\n",
    "                # Update start time for the next iteration\n",
    "                last_event_time = batch_events[-1].get_time()\n",
    "                # Increment by 1 second to avoid duplicate events\n",
    "                start_time = (last_event_time + timedelta(seconds=time_increment)).isoformat()\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        print(\"No events found in range.\")\n",
    "\n",
    "    time.sleep(poll_interval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_AARE(D, D_bar, T):\n",
    "    if T < 5:\n",
    "        raise ValueError(\"T must be greater than or equal to 5\")\n",
    "    \n",
    "    # Calculate the absolute relative errors for the required time period\n",
    "    absolute_relative_errors = torch.abs(D[T-3:T+1] - D_bar[T-3:T+1]) / D[T-3:T+1]\n",
    "    \n",
    "    # Calculate the average absolute relative error\n",
    "    AARE_star = torch.mean(absolute_relative_errors)\n",
    "    \n",
    "    return AARE_star\n",
    "\n",
    "# Example usage:\n",
    "# D = torch.tensor([...]) # Tensor containing D values\n",
    "# D_bar = torch.tensor([...]) # Tensor containing D_bar values\n",
    "# T = current time period (must be >= 5)\n",
    "# AARE_star_T = calculate_AARE_star(D, D_bar, T)\n",
    "\n",
    "def calculate_mu_AARE(AARE, T, W):\n",
    "    if 7 <= T < W + 4:\n",
    "        mu_AARE_star = torch.mean(AARE[4:T])\n",
    "    elif T >= W + 4:\n",
    "        mu_AARE_star = torch.mean(AARE[T-W:T])\n",
    "    else:\n",
    "        raise ValueError(\"T must be greater than or equal to 7\")\n",
    "    return mu_AARE_star\n",
    "\n",
    "def calculate_sigma(AARE, mu_AARE, T, W):\n",
    "    if 7 <= T < W + 4:\n",
    "        sigma_star = torch.sqrt(torch.sum((AARE[4:T] - mu_AARE) ** 2) / (T - 4))\n",
    "    elif T >= W + 4:\n",
    "        sigma_star = torch.sqrt(torch.sum((AARE[T-W:T] - mu_AARE) ** 2) / W)\n",
    "    else:\n",
    "        raise ValueError(\"T must be greater than or equal to 7\")\n",
    "    return sigma_star\n",
    "\n",
    "def calculate_Thd(AARE, T, W):\n",
    "    mu_AARE = calculate_mu_AARE(AARE, T, W)\n",
    "    sigma = calculate_sigma(AARE, mu_AARE, T, W)\n",
    "    Thd = mu_AARE + 3 * sigma\n",
    "    return Thd\n",
    "\n",
    "# Example usage:\n",
    "# AARE_star = torch.tensor([...]) # A PyTorch tensor containing AARE* values\n",
    "# T = current time period (must be >= 7)\n",
    "# W = window size for the moving average and standard deviation\n",
    "# Thd_star = calculate_Thd_star(AARE_star, T, W)\n",
    "\n",
    "\n",
    "\n",
    "# Let T be the current time point and T starts from 0; Let flag* be True;\n",
    "\n",
    "While time has advanced {\n",
    "    Collect data point D_T\n",
    "    \n",
    "    if T >= 2 && T < 5 {\n",
    "        Train LSTM model by taking D_T-2, D_T-1 and D_T as training data (X and Y values for the three datapoints)\n",
    "        Let M* be the resulting model and use M* to predict D_T+1\n",
    "   \n",
    "    } elif T >= 5 && T < 7 {\n",
    "        Calculate AARE_T* based on Equation 5\n",
    "        Train LSTM model by taking D_T-2, D_T-1 and D_T as training data (X and Y values for the three datapoints)\n",
    "        Let M* be the resulting model and use M* to predict D_T+1\n",
    "        \n",
    "    } elif T >= 7 && flag* == True {\n",
    "        if T != 7 {Use M* to Predict D_T}\n",
    "        Calculate AARE_T* based on Equation 5\n",
    "        Calculate Thd* based on Equation 6\n",
    "\n",
    "        if AARE_T* <= Thd* {D_T* is not considered an anomaly}\n",
    "\n",
    "        else {\n",
    "            Train LSTM model by taking D_T-3, D_T-2 and D_T-1 as training data\n",
    "            Use the model to repredict D_T\n",
    "            Re-calculate AARE_T* based on Equation 5\n",
    "            Re-calculate Thd* based on Equation 6\n",
    "\n",
    "            if AARE_T* <= Thd* {\n",
    "                D_T is not consideren an anomaly\n",
    "                Replace M* with the new LSTM-model\n",
    "                Let flag* be True\n",
    "\n",
    "            } else {\n",
    "                D_T is reported as an anomaly immediately\n",
    "                Let flag* be True\n",
    "\n",
    "            }\n",
    "        }\n",
    "    } elif T >= 7 && flag* == False {\n",
    "        Train LSTM model by taking D_T-3, D_T-2 and D_T-1 as training data\n",
    "        Use the LSTM model to predict D_T \n",
    "        Calculate AARE_T* based on Equation 5\n",
    "        Calculate Thd* based on Equation 6\n",
    "\n",
    "        if AARE_T* <= Thd* {\n",
    "            D_T is not considered an anomaly\n",
    "            Replace M* with the new LSTM-model\n",
    "            Let flag* be True\n",
    "        } else {\n",
    "            D_T is reported as an anomaly immediately\n",
    "            Let flag* be False\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
