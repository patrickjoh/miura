{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_model import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RePAD2\n",
    "def calculate_aare(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the Average Absolute Relative Error (AARE) between actual and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - actual (list or array): The actual values.\n",
    "    - predicted (list or array): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    - float: The AARE value.\n",
    "    \"\"\"\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"The length of actual and predicted values must be the same.\")\n",
    "\n",
    "    # Calculate the absolute relative errors\n",
    "    absolute_relative_errors = [abs((a - p) / a) for a, p in zip(actual, predicted) if a != 0]\n",
    "\n",
    "    # Calculate the average of these errors\n",
    "    aare = sum(absolute_relative_errors) / len(absolute_relative_errors)\n",
    "    \n",
    "    return aare\n",
    "\n",
    "def calculate_threshold(aare_values):\n",
    "    \"\"\"\n",
    "    Calculate the threshold value (Thd) based on an array of AARE values.\n",
    "    Thd is defined as the mean of the AARE values plus three times their standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - aare_values (array-like): An array of AARE values.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated threshold value (Thd).\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation of the AARE values\n",
    "    mean_aare = np.mean(aare_values)\n",
    "    std_aare = np.std(aare_values)\n",
    "    \n",
    "    # Calculate Thd\n",
    "    thd = mean_aare + 3 * std_aare\n",
    "    \n",
    "    return thd\n",
    "\n",
    "# Function for creating model\n",
    "def train_model(train_events):\n",
    "    tensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "    tensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "    # Create an instance of the LSTM model\n",
    "    model = LSTM(tensor_x, tensor_y, input_size=1, hidden_size=10, num_layers=1, output_size=1, batch_size=3, num_epochs=50, learning_rate=0.005)\n",
    "    model.train_model() # Train the model\n",
    "\n",
    "    return model\n",
    "\n",
    "def report_anomaly(value, timestamp, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"anomaly\")\\\n",
    "        .tag(\"host\", \"MIURA\")\\\n",
    "        .field(\"value\", value)\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    write_api.write(bucket=\"system_state\", org=\"ORG\", record=point)\n",
    "    print(f\"Anomalous event sent to InfluxDB: Value={value}, Time={timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPAD2 Algorithm ###\n",
    "\n",
    "\"\"\"\n",
    "THE PLAN\n",
    "\n",
    "Making the program start from any predefined time, and then continue to fetch data from that time and onwards.\n",
    "And so it can process older data and then catch up to the present time.\n",
    "\n",
    "It therefore processes a batch of 3 from the earliest timestamp in the range, and then updates the start time for the next iteration \n",
    "by incrementing the start time by a set time to both avoid duplicate events and to eventually catch up to the present time.\n",
    "\n",
    "The program will run indefinitely, and will continue to fetch data from the InfluxDB and process it in batches of 3 until the program is stopped.\n",
    "I there are not enough events for a batch, the program will wait for a set time before trying again.\n",
    "When a batch of three is available it will be processed and the it will again wait for another event to be available.\n",
    "\n",
    "This way it is both flexible and efficient, and can be easily used to process either data in real-time or historical data\n",
    "\n",
    "\n",
    "For each batch it follows the algorithm of RePAD2\n",
    "\n",
    "\n",
    "To-Do:\n",
    "\n",
    "Store actual values (Store whole event?) with predicted values in sliding window \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Testing of InfluxDB with LSTM\n",
    "# MÃ¥ installeres influxdb-client \"pip install influxdb-client\"\n",
    "# https://www.influxdata.com/blog/getting-started-with-python-and-influxdb-v2-0/\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "measurement = \"cpu_utilization\"\n",
    "\n",
    "# Instantiate the QueryAPI\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Sliding window for Threshold\n",
    "#sliding_window = deque(maxlen=8064)\n",
    "actual_values = deque(maxlen=8064)\n",
    "predicted_values = deque(maxlen=8064)\n",
    "sliding_window_AARE = deque(maxlen=8064)\n",
    "\n",
    "# Time parameters\n",
    "poll_interval = 1\n",
    "time_increment = 1\n",
    "start_time = \"2014-04-10T00:00:00Z\"\n",
    "\n",
    "# RePAD2 specific\n",
    "T = 0\n",
    "flag = True \n",
    "M = None # Model\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Construct the Flux query\n",
    "    query = f'''\n",
    "    from(bucket: \"{bucket}\")\n",
    "     |> range(start: time(v: \"{start_time}\"))\n",
    "     |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "    '''\n",
    "        \n",
    "    # Query the data\n",
    "    events = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "    if len(events) >= 4: # Need at least 4 to predict next and compare\n",
    "        for i in range(len(events) - 3):\n",
    "            batch_events = events[i:i+3]\n",
    "            next_event = events[i+3]\n",
    "\n",
    "            # Testing    \n",
    "            T += 1\n",
    "            print(f'T: {T}')\n",
    "            #time.sleep(1)\n",
    "\n",
    "        # Set T to the length of the sliding \n",
    "            if T >= 2 and T < 5: # 3 total values when T = 2\n",
    "                M = train_model([event.get_value() for event in list(batch_events)])\n",
    "                pred_D_T_plus_1 = M.predict_next()\n",
    "                # Append the event and its prediction to the sliding window\n",
    "                actual_values.append(next_event.get_value())\n",
    "                predicted_values.append(pred_D_T_plus_1)\n",
    "\n",
    "            elif T >= 5 and T < 7:\n",
    "                # Calculate AARE and append to sliding window\n",
    "                AARE_T = calculate_aare(actual_values, predicted_values)\n",
    "                sliding_window_AARE.append(AARE_T)\n",
    "                M = train_model([event.get_value() for event in list(batch_events)])\n",
    "                pred_D_T_plus_1 = M.predict_next()\n",
    "                # Append the event and its prediction to the sliding window\n",
    "                actual_values.append(next_event.get_value())\n",
    "                predicted_values.append(pred_D_T_plus_1)\n",
    "\n",
    "                #print(f'Pred_D_T: {pred_D_T_plus_1}')\n",
    "\n",
    "            elif T >= 7 and flag == True:\n",
    "                if T != 7: # Use M to precdict D_T\n",
    "                    pred_D_T = M.predict_next()\n",
    "                    # Append the event and its prediction to the sliding window\n",
    "                    actual_values.append(next_event.get_value())\n",
    "                    predicted_values.append(pred_D_T)\n",
    "\n",
    "                # Calculate AARE and append to sliding window\n",
    "                AARE_T = calculate_aare(actual_values, predicted_values)\n",
    "                sliding_window_AARE.append(AARE_T)\n",
    "                # Calculate Thd\n",
    "                Thd = calculate_threshold(sliding_window_AARE)\n",
    "                \n",
    "                if AARE_T <= Thd: pass # Calculate AARE and append to sliding window\n",
    "                else:\n",
    "                    # Pop the right of the sliding window\n",
    "                    actual_values.pop()\n",
    "                    predicted_values.pop()\n",
    "                    # Train an LSTM model with D_T-3, D_T-2, D_T-1\n",
    "                    model = train_model([event.get_value() for event in list(batch_events)])\n",
    "                    # Use the model to predict D_T\n",
    "                    pred_D_T = model.predict_next()\n",
    "                    \n",
    "                    # Append the event and its prediction to the sliding window\n",
    "                    actual_values.append(next_event.get_value())\n",
    "                    predicted_values.append(pred_D_T)\n",
    "\n",
    "                    # Re-calculate AARE_T\n",
    "                    AARE_T = calculate_aare(actual_values, predicted_values)\n",
    "                    sliding_window_AARE.append(AARE_T)\n",
    "                    # Re-calculate Thd\n",
    "                    Thd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "                    if AARE_T <= Thd:\n",
    "                        # D_T is not reported as anomaly\n",
    "                        # Replace M with the new model\n",
    "                        M = model\n",
    "                        # Update flag to True\n",
    "                        flag = True\n",
    "\n",
    "                    else:\n",
    "                        # D_T reported as anomaly immediately\n",
    "                        report_anomaly(next_event.get_value(), next_event.get_time(), write_api)\n",
    "                        # Update flag to False\n",
    "                        flag = False\n",
    "            \n",
    "            elif T >= 7 and flag == False:\n",
    "                # Train an LSTM model with D_T-3, D_T-2, D_T-1\n",
    "                model = train_model([event.get_value() for event in list(batch_events)])\n",
    "                # Use the model to predict D_T\n",
    "                pred_D_T = model.predict_next()\n",
    "                # Append the event and its prediction to the sliding window\n",
    "                actual_values.append(next_event.get_value())\n",
    "                predicted_values.append(pred_D_T)\n",
    "\n",
    "                # Calculate AARE_T\n",
    "                AARE_T = calculate_aare(actual_values, predicted_values)\n",
    "                sliding_window_AARE.append(AARE_T)\n",
    "                # Calculate Thd\n",
    "                Thd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "                if AARE_T <= Thd:\n",
    "                    # D_T is not reported as anomaly\n",
    "                    # Replace M with the new model\n",
    "                    M = model\n",
    "                    # Update flag to True\n",
    "                    flag = True\n",
    "\n",
    "                else:\n",
    "                    # D_T reported as anomaly immediately\n",
    "                    report_anomaly(next_event.get_value(), next_event.get_time(), write_api)\n",
    "                    # Update flag to False\n",
    "                    flag = False\n",
    "\n",
    "\n",
    "            if T > 2:\n",
    "                # Print newest value in the predicted_values deque\n",
    "                print(f'Predicted value: {predicted_values[-1]}')\n",
    "\n",
    "\n",
    "        # Update start time for the next iteration\n",
    "        last_event_time = batch_events[-1].get_time()\n",
    "        # Increment by 1 second to avoid duplicate events\n",
    "        start_time = (last_event_time + timedelta(seconds=time_increment)).isoformat()\n",
    "                \n",
    "\n",
    "    else:\n",
    "        print(\"No events found in range.\")\n",
    "\n",
    "    time.sleep(poll_interval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
